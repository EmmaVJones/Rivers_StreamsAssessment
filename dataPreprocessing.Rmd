---
title: "2020 IR R&S Data Preprocessing"
author: "Emma Jones"
date: "December 14, 2018"
output: html_document
---

Run in R 3.5.1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
library(readxl)

```

This document walks users through the requisite data preprocessing steps for the 2020 IR Rivers and Streams Assessment decision support application. All initial steps are tested on 2018 IR data and thus need to be rerun for 2020 data when those datasets become available.

## Input data

#### Conventionals
Bring in Roger's conventionals dataset.
```{r conventionals2018}
conventionals <- read_excel('workingDatasets/CONVENTIONALS_20171010.xlsx',sheet = 'CONVENTIONALS')
glimpse(conventionals)
```

#### WQS
Bring in updated WQS for New, Roanoke, and James basins. To get here, I took the updated basin files from each of their respective geodatabases, pulled out the riverine layer, exported to shapefile, and put in C:/updatedWQS directory for easy access.
```{r WQS}
#example:
WQS <- st_read('C:/updatedWQS/updatedRoanoke.shp')
glimpse(WQS)
```


#### Last Cycle's Station's Table 
Bring in the previous stations table (draft still when writing this script) to help organize previous assessment decisions and assessment units.
```{r stationsTable}
stationsTable <- read_excel('workingDatasets/STREAMS_ir_mon_stations_20Nov2018.xlsx')
glimpse(stationsTable)
```


## Data manipulation
To speed application building, we subset data to just the BRRO region.

```{r filterConventionals}
conventionals <- filter(conventionals, FDT_STA_ID %in% stationsTable$STATION_ID)
glimpse(conventionals)
```

So right now, conventionals already has the VAHU5 and VAHU6 designations, stationsTable already has previous ID305B designations and previous violation counts, and all we need to proceed (for field parameters and basic chemistry) is the appropriate WQS info attached to each StationID.

## Snap Stations to WQS

Using the wokring copy of the snapFunction, we will snap unique stations from conventionals to WQS. It is important to use conventionals because these will be the 'real' list of stations we need to assess each window. If we went from the stationsTable then we could miss stations if they were not in the previous cycle. 

Eventually, after the assessors have updated stationsTable to include appropriate WQS, we could add a step that first joins unique stations from conventionals to last cycle's stationsTable to significantly reduce the number of stations we need to attach new WQS information to.

For now, let's just work in the Roanoke Basin. We will also save some QA steps and only initially work with stations that connected to one geometry within a 10-50 meter buffer distance.

```{r snapWQS}
source('snapFunctions.R')

BRRO_Sites_sf <- filter(conventionals, Basin == 'Roanoke River Basin') %>% # just Roanoke
  distinct(FDT_STA_ID, .keep_all = TRUE) %>% # Just unique sites
  select(FDT_STA_ID:FDT_SPG_CODE,STA_LV2_CODE:STA_CBP_NAME) %>% # drop sample data
  st_as_sf(coords = c("Longitude", "Latitude"), 
           remove = F, # don't remove these lat/lon cols from df
           crs = 4269) %>% # add projection, needs to be geographic for now bc entering lat/lng, 
  st_transform( st_crs(WQS)) # now change crs to Albers to make snapping work

#snapList_BRRO <- snap_Points_to_Feature_List(BRRO_Sites_sf,'FDT_STA_ID',WQS, seq(10,50,by=10))
#saveRDS(snapList_BRRO, 'workingDatasets/snapList_BRRO.RDS')
snapList_BRRO <- readRDS('workingDatasets/snapList_BRRO.RDS')

```

Subset just the sites that connected to one segment.

```{r oneSegmentDF}

# function to find sites with +1 segment
snapCheck <- function(successDataFrame){
  successDataFrame %>%
    group_by(`Point Unique Identifier`) %>%
    filter(n()>1)
}

tooMany <- snapCheck(snapList_BRRO[['sf_output']])

sites <- filter(snapList_BRRO[['sf_output']], !(`Point Unique Identifier` %in% tooMany$`Point Unique Identifier`))

#saveRDS(sites,'workingDatasets/BRROsites_ROA.RDS')
```

Now join those few columns from conventionals that we want with VAHU info to make new StationTable dataset. Lose stream segment geometry bc it is not needed for the rest of app.

```{r stationsTable new format}
BRRO_Sites <- BRRO_Sites_sf %>%
  st_set_geometry(NULL) 

sites <- mutate(sites, FDT_STA_ID = `Point Unique Identifier`) %>%
  left_join(BRRO_Sites, by = 'FDT_STA_ID') %>%
  st_set_geometry(NULL) %>%
  select(FDT_STA_ID, everything(), -c(`Point Unique Identifier`))
```

