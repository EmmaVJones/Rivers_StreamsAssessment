---
title: "Preparing Data for Mary"
author: "Emma Jones"
date: "January 29, 2019"
output: html_document
---

Run in R 3.5.1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
library(readxl)
library(mapview)
library(leaflet)

```

This document walks users through the requisite data preprocessing steps for the 2020 IR Rivers and Streams Assessment decision support application. All initial steps are tested on 2018 IR data and thus need to be rerun for 2020 data when those datasets become available.


### Mary Version

This document demonstrates the necessary steps to get (any) regional office up to speed with prerequisite data organization/processing steps to run the 2020 IR. This version works with BRRO data (WCRO and SCRO) to get Mary ready for assessing.

## Input data

#### Conventionals
Bring in Roger's conventionals dataset. Make it a csv immediately to speed up rendering in app. This is the final data pull from Roger for the 2018 IR. As of today, the 2020 final IR pull is not available. **Subsitute 2020 data in when available.**

```{r conventionals2018}
#conventionals <- read_excel('workingDatasets/CONVENTIONALS_20171010.xlsx',sheet = 'CONVENTIONALS')
#conventionals$FDT_DATE_TIME2 <- as.POSIXct(conventionals$FDT_DATE_TIME, format="%m/%d/%y %H:%M")
#write.csv(conventionals, 'workingDatasets/CONVENTIONALS_20171010.csv', row.names=F)

conventionals <- suppressWarnings(suppressMessages(read_csv('workingDatasets/CONVENTIONALS_20171010.csv')))
#glimpse(conventionals)
```

Work with just BRRO for now. Skip step when working up full state data.

```{r BRROconventionals}
conventionals <- filter(conventionals, Deq_Region == 'Blue Ridge') 
```

Now we need to make a dataset of all UNIQUE StationID's for the region of interest to work with.

```{r BRROconventionalsDistinct}

conventionals_D <- distinct(conventionals, FDT_STA_ID, .keep_all = T) %>%
  select(FDT_STA_ID:FDT_SPG_CODE, STA_LV2_CODE:STA_CBP_NAME)# drop data to avoid any confusion
rm(conventionals)
```


#### Last Cycle's Stations Table

This is a draft from Mary right now, but everything should be in there (Stations and ID305B's). Keep determinations for now even though they are draft.

**There are duplicated rows in this dataset that royally F things up. I have filtered them out for now. Not sure if correct.**

```{r stationTable}
stationTable <- read_excel('data/Emma_Stations2018IR_Draft_Dec.xlsx')

stationTable1 <- stationTable %>%
  group_by(STATION_ID) %>%
  mutate(extra= n()) %>%
  select(STATION_ID, extra, everything())

stationTable2 <- distinct(stationTable, STATION_ID, ID305B_1, ID305B_2, ID305B_3, .keep_all = T)%>%
  group_by(STATION_ID) %>%
  mutate(extra= n()) %>%
  select(STATION_ID, extra, everything()) %>% # still extras so just take distinct STATION_ID 
  distinct(STATION_ID,.keep_all = T) %>%
  select(-extra)
rm(stationTable1)
```


#### Assessment Spatial Layer (last cycle)

Since 2018 isn't published yet, working from 2016 final layer. 

```{r Assessment Unit shapefile}
AUs <- st_read('GIS/va_2016_aus_riverine_WGS84.shp') %>%
  st_transform(crs = 102003) # convert to Albers Equal Area just for snapping
```



## Data Organization Step 1: Get AU's from previous cycle for conventionals data.

This step uses last cycle's ID305B columns and joins that information to the conventionals StationID's. This is where all assessments should start. This information **COULD** change if an AU is split through this assessment cycle's assessment process.

```{r join unique StationIDs}

BRRO_Sites <- mutate(conventionals_D, STATION_ID = FDT_STA_ID) %>% # make joining column
  left_join(stationTable2, by='STATION_ID') %>% # join to get ID305B info
  st_as_sf(coords = c("Longitude", "Latitude"),  # make spatial layer while at it
           remove = F, # don't remove these lat/lon cols from df
           crs = 4269) %>% # add projection, needs to be geographic for now bc entering lat/lng, 
  st_transform( st_crs(AUs)) # now change crs to Albers to make snapping work
  
sum(!is.na(BRRO_Sites$ID305B_1))/nrow(BRRO_Sites)*100 # 73% have last cycle AU info
sum(is.na(BRRO_Sites$ID305B_1))/nrow(BRRO_Sites)*100 # 27% don't have last cycle AU info

```


So basics statistics for now, comparing 2018 IR data from Roger to Mary's almost finished 2018 IR Stations table, still missing 27% of stations ID_305B info??? 

```{r BRRO sites without AU info}
BRRO_Sites_noAU <- filter(BRRO_Sites, is.na(ID305B_1))
```

Looking at the BRRO_Sites_noAU dataset we can see the majority of sites are from other regions, but there are still quite a few WCRO stations without AU info. The majority of these are lake stations (STA_LV1_CODE == 'RESERV'). Makes sense, but we will need to fix that eventually.

## Data Organization Step 1.1: Automate AU snapping for StationID's that did not immediately join to last cycle's Station Table 

```{r snapAUs}
source('snapFunctions.R')

snapList_AU <- snap_Points_to_Feature_List(BRRO_Sites_noAU,'FDT_STA_ID',AUs, seq(10,50,by=10))

# function to find sites with +1 segment
snapCheck <- function(successDataFrame){
  successDataFrame %>%
    group_by(`Point Unique Identifier`) %>%
    filter(n()>1)
}

# sites that snapped to too many segments
tooMany <- snapCheck(snapList_AU[['sf_output']])
length(unique(tooMany$`Point Unique Identifier`)) #13

# perfect sites
sites <- filter(snapList_AU[['sf_output']], !(`Point Unique Identifier` %in% tooMany$`Point Unique Identifier`)) %>%
  st_set_geometry(NULL) %>%
  mutate(FDT_STA_ID=`Point Unique Identifier`)
nrow(sites) #157


#saveRDS(snapList_AU, 'data/allBRRO_snapList_AU.RDS')
#snapList_AU <- readRDS('data/allBRRO_snapList_AU.RDS')
```

So out of 230 stations we tried to snap to AUs, 157 snapped to only one segment (good), 13 snapped to more than one segment (okay), and 60 snapped to no segments (not awesome).


## Data Organization Step 1.2: Fix StationID's that snapped to too many segments



Now use shiny gadget to help user select appropriate AU for each of the sites that snapped to too many segments.

```{r my attempt at shiny gadget}
tooMany <- snapCheck(snapList_AU[['sf_output']] ) %>%
  st_transform(4326)# project to WGS84 for plotting
tooMany1 <- filter(tooMany, `Point Unique Identifier` == '2-APP143.57')

siteWithTooMany <- filter(BRRO_Sites_noAU, FDT_STA_ID %in% unique(tooMany$`Point Unique Identifier`)) %>%
  st_transform(4326)# project to WGS84 for plotting
siteWithTooMany1 <- filter(siteWithTooMany, FDT_STA_ID =='2-APP143.57')

sfLines <- tooMany1
sfPoint <- siteWithTooMany1

test <- AUselecter(sfLines, sfPoint) 

AUselecter <- function(sfLines, sfPoint) {
  ui <- miniPage(
  gadgetTitleBar("AU Selection", right = miniTitleBarButton("done", "Accept", primary = TRUE)),
  miniTabstripPanel(
    miniTabPanel("Site", icon = icon("mouse-pointer"),#sliders
                 miniContentPanel(
                   uiOutput('StationID'), br(),
                   radioButtons("auChosen", "Choose the correct assessment unit for the site", 
                                choices = sfLines$ID305B, selected = NULL)#,
                   #miniButtonBlock(
                   #  actionButton("chooseAU", "Choose AU"))
                   )),
    miniTabPanel("Map", icon = icon("map-o"),
      miniContentPanel(padding = 0,
        leafletOutput("map", height = "100%")
      )),
    miniTabPanel('Table', icon = icon("table"),
      miniContentPanel(
        DT::dataTableOutput("table")))
    )
)


server <- function(input, output, session) {
  
  output$StationID <- renderUI({strong(paste('StationID:',unique(sfLines$`Point Unique Identifier`)))})
  
  output$map <- renderLeaflet({
    m <- mapview(sfLines, label= sfLines$ID305B, layer.name = c('AUs snapped to selected site'), 
            zcol = "ID305B", legend=FALSE,
            popup= popupTable(sfLines, zcol=c("ID305B","MILES","CYCLE","WATER_NAME","LOCATION" )),
            map.types = c("OpenStreetMap","Esri.WorldImagery")) +
      mapview(sfPoint, color = 'yellow',lwd= 5, label= sfPoint$FDT_STA_ID, 
              layer.name = c('Selected Site'),
              popup= popupTable(sfPoint, zcol=c('FDT_STA_ID','STA_DESC')),
              map.types = c("OpenStreetMap","Esri.WorldImagery"))
    m@map 
      
  })

  output$table <- DT::renderDataTable({
    z <- sfLines %>% st_set_geometry(NULL)
    DT::datatable(z, rownames = FALSE, options= list(pageLength = nrow(z), scrollY = "290px", dom='t'))
  })
  
  #observeEvent(input$chooseAU, {
  #   userValue <- data.frame(StationID = unique(sfPoint$FDT_STA_ID), ID305B = input$auChosen)
  #})
  
   observeEvent(input$done, {
     userValue <- data.frame(StationID = as.character(unique(sfPoint$FDT_STA_ID)), 
                             ID305B = as.character(input$auChosen))
     stopApp(userValue)
  })
}

runGadget(shinyApp(ui, server))

}

```



```{r loop attempt, eval=FALSE}
# make test dataset with 4 sites
tooMany <- snapCheck(snapList_AU[['sf_output']] ) %>%
  st_transform(4326)# project to WGS84 for plotting
tooMany4 <- filter(tooMany, `Point Unique Identifier` %in% unique(tooMany$`Point Unique Identifier`)[1:4])

siteWithTooMany <- filter(BRRO_Sites_noAU, FDT_STA_ID %in% unique(tooMany$`Point Unique Identifier`)) %>%
  st_transform(4326)# project to WGS84 for plotting
siteWithTooMany4 <- filter(siteWithTooMany, FDT_STA_ID %in% tooMany4$`Point Unique Identifier`)



StationID <- as.character(nrow(siteWithTooMany4))
ID305B <- as.character(nrow(siteWithTooMany4))

for (i in 1:nrow(siteWithTooMany4)){
  zz <- AUselecter(filter(tooMany4, `Point Unique Identifier` %in% siteWithTooMany4[i,]), 
                          siteWithTooMany4[i,]) 
  StationID[i] <- as.character(zz[1][[1]])
  ID305B[i] <- as.character(zz[2][[1]])
}

results  <- data.frame(StationID, ID305B, stringsAsFactors = FALSE)
```


So in recap, here's the workflow: (need to make function to feed dataset I give assessors into the gadget and another to append results to perfect list)

```{r fix too many snaps}
# make spatial forms of each object in WGS 84
tooMany <- snapCheck(snapList_AU[['sf_output']] ) %>%
  st_transform(4326)# project to WGS84 for plotting
siteWithTooMany <- filter(BRRO_Sites_noAU, FDT_STA_ID %in% unique(tooMany$`Point Unique Identifier`)) %>%
  st_transform(4326)# project to WGS84 for plotting

# empty place to put results, save time on processing and dont put in dataframe immediately bc
# looping is already slow enough
StationID <- as.character(nrow(siteWithTooMany))
ID305B <- as.character(nrow(siteWithTooMany))

for (i in 1:nrow(siteWithTooMany)){
  zz <- AUselecter(filter(tooMany, `Point Unique Identifier` %in% siteWithTooMany[i,]), 
                          siteWithTooMany[i,]) 
  StationID[i] <- as.character(zz[1][[1]])
  ID305B[i] <- as.character(zz[2][[1]])
}

results  <- data.frame(StationID, ID305B, stringsAsFactors = FALSE)

```


To do list:
- make function to get from snapping function to AU chooser gadget
- make function to merge results to existing au results
- organize au results into just csv an assessor could in theory fill out by themselves
- blow up gadget to handle choosing AU more than 50m away, maybe do 100 m buffer and thow that into gadget map?
- do logic for WQS snapping

